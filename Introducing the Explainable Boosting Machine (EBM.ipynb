{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267215cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run benchmark script, you will need to install XGBoost \n",
    "# (pip install XGBoost)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_breast_data():\n",
    "    breast = load_breast_cancer()\n",
    "    feature_names = list(breast.feature_names)\n",
    "    X, y = pd.DataFrame(breast.data, columns=feature_names), breast.target\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "        },\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_adult_data():\n",
    "    df = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        header=None)\n",
    "    df.columns = [\n",
    "        \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "        \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "        \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "    ]\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def load_heart_data():\n",
    "    # https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "    df = pd.read_csv('https://www.kaggle.com/datasets/zhaoyingzhu/heartcsv',header=None)\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_credit_data():\n",
    "    # https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "    df = pd.read_csv('https://www.kaggle.com/mlg-ulb/creditcardfraud',header=None)\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_telco_churn_data():\n",
    "    # https://www.kaggle.com/blastchar/telco-customer-churn/downloads/WA_Fn-UseC_-Telco-Customer-Churn.csv/1\n",
    "    df = pd.read_csv('https://www.kaggle.com/blastchar/telco-customer-churn/downloads/WA_Fn-UseC_-Telco-Customer-Churn.csv/1',header=None)\n",
    "    train_cols = df.columns[1:-1] # First column is an ID\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label] # 'Yes, No'\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2775e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1374b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "\n",
    "def format_n(x):\n",
    "    return \"{0:.3f}\".format(x)\n",
    "\n",
    "def process_model(clf, name, X, y, n_splits=3):\n",
    "    # Evaluate model\n",
    "    ss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25, random_state=1337)\n",
    "    scores = cross_validate(\n",
    "        clf, X, y, scoring='roc_auc', cv=ss,\n",
    "        n_jobs=None, return_estimator=True\n",
    "    )\n",
    "\n",
    "    record = dict()\n",
    "    record['model_name'] = name\n",
    "    record['fit_time_mean'] = format_n(np.mean(scores['fit_time']))\n",
    "    record['fit_time_std'] = format_n(np.std(scores['fit_time']))\n",
    "    record['test_score_mean'] = format_n(np.mean(scores['test_score']))\n",
    "    record['test_score_std'] = format_n(np.std(scores['test_score']))\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_models(dataset_name, X, y, ct=None, n_splits=3, random_state=1337):\n",
    "    if ct is None:\n",
    "        is_cat = np.array([dt.kind == 'O' for dt in X.dtypes])\n",
    "        cat_cols = X.columns.values[is_cat]\n",
    "        num_cols = X.columns.values[~is_cat]\n",
    "\n",
    "        cat_ohe_step = ('ohe', OneHotEncoder(sparse=False,\n",
    "                                             handle_unknown='ignore'))\n",
    "\n",
    "        cat_pipe = Pipeline([cat_ohe_step])\n",
    "        num_pipe = Pipeline([('identity', FunctionTransformer())])\n",
    "        transformers = [\n",
    "            ('cat', cat_pipe, cat_cols),\n",
    "            ('num', num_pipe, num_cols)\n",
    "        ]\n",
    "        ct = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    summary_record = {}\n",
    "    summary_record['dataset_name'] = dataset_name\n",
    "    print()\n",
    "    print('-' * 78)\n",
    "    print(dataset_name)\n",
    "    print('-' * 78)\n",
    "    print(summary_record)\n",
    "    print()\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('std', StandardScaler()),\n",
    "        ('lr', LogisticRegression(random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'lr', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        # n_estimators updated from 10 to 100 due to sci-kit defaults changing in future versions\n",
    "        ('rf-100', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'rf-100', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('xgb', XGBClassifier(random_state=random_state, eval_metric='logloss')),\n",
    "    ])\n",
    "    record = process_model(pipe, 'xgb', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    # No pipeline needed due to EBM handling string datatypes\n",
    "    ebm_inter = ExplainableBoostingClassifier(n_jobs=-1, random_state=random_state)\n",
    "    record = process_model(ebm_inter, 'ebm', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f467677",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "n_splits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ba8d6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_heart_data()\n\u001b[0;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m benchmark_models(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheart\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], n_splits\u001b[38;5;241m=\u001b[39mn_splits)\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[19], line 50\u001b[0m, in \u001b[0;36mload_heart_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_heart_data\u001b[39m():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# https://www.kaggle.com/ronitf/heart-disease-uci\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/datasets/zhaoyingzhu/heartcsv\u001b[39m\u001b[38;5;124m'\u001b[39m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     51\u001b[0m     train_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     52\u001b[0m     label \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 9, saw 2\n"
     ]
    }
   ],
   "source": [
    "dataset = load_heart_data()\n",
    "result = benchmark_models('heart', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3989e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "breast-cancer\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'breast-cancer'}\n",
      "\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.011', 'fit_time_std': '0.001', 'test_score_mean': '0.994', 'test_score_std': '0.006'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '0.728', 'fit_time_std': '0.824', 'test_score_mean': '0.992', 'test_score_std': '0.009'}\n",
      "{'model_name': 'xgb', 'fit_time_mean': '0.053', 'fit_time_std': '0.005', 'test_score_mean': '0.992', 'test_score_std': '0.010'}\n",
      "{'model_name': 'ebm', 'fit_time_mean': '1.823', 'fit_time_std': '0.489', 'test_score_mean': '0.995', 'test_score_std': '0.005'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_breast_data()\n",
    "result = benchmark_models('breast-cancer', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c353227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "adult\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'adult'}\n",
      "\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.504', 'fit_time_std': '0.023', 'test_score_mean': '0.906', 'test_score_std': '0.003'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '2.443', 'fit_time_std': '0.039', 'test_score_mean': '0.903', 'test_score_std': '0.002'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1467, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [' <=50K' ' >50K']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_adult_data()\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m benchmark_models(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], n_splits\u001b[38;5;241m=\u001b[39mn_splits)\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[20], line 88\u001b[0m, in \u001b[0;36mbenchmark_models\u001b[1;34m(dataset_name, X, y, ct, n_splits, random_state)\u001b[0m\n\u001b[0;32m     82\u001b[0m records\u001b[38;5;241m.\u001b[39mappend(record)\n\u001b[0;32m     84\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     85\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m'\u001b[39m, ct),\n\u001b[0;32m     86\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(random_state\u001b[38;5;241m=\u001b[39mrandom_state, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     87\u001b[0m ])\n\u001b[1;32m---> 88\u001b[0m record \u001b[38;5;241m=\u001b[39m process_model(pipe, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, X, y, n_splits\u001b[38;5;241m=\u001b[39mn_splits)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(record)\n\u001b[0;32m     90\u001b[0m record\u001b[38;5;241m.\u001b[39mupdate(summary_record)\n",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m, in \u001b[0;36mprocess_model\u001b[1;34m(clf, name, X, y, n_splits)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_model\u001b[39m(clf, name, X, y, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     ss \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39mn_splits, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1337\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m     21\u001b[0m         clf, X, y, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mss,\n\u001b[0;32m     22\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m     26\u001b[0m     record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\Users\\sdiedhio\\AppData\\Local\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1467, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_adult_data()\n",
    "result = benchmark_models('adult', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec8ee0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_credit_data()\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m benchmark_models(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit-fraud\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], n_splits\u001b[38;5;241m=\u001b[39mn_splits)\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m, in \u001b[0;36mbenchmark_models\u001b[1;34m(dataset_name, X, y, ct, n_splits, random_state)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     is_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([dt\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtypes])\n\u001b[1;32m---> 39\u001b[0m     cat_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues[is_cat]\n\u001b[0;32m     40\u001b[0m     num_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m~\u001b[39mis_cat]\n\u001b[0;32m     42\u001b[0m     cat_ohe_step \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mohe\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     43\u001b[0m                                          handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "dataset = load_credit_data()\n",
    "result = benchmark_models('credit-fraud', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aec5e307",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_telco_churn_data()\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m benchmark_models(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtelco-churn\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m], dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m, in \u001b[0;36mbenchmark_models\u001b[1;34m(dataset_name, X, y, ct, n_splits, random_state)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     is_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([dt\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtypes])\n\u001b[1;32m---> 39\u001b[0m     cat_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues[is_cat]\n\u001b[0;32m     40\u001b[0m     num_cols \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m~\u001b[39mis_cat]\n\u001b[0;32m     42\u001b[0m     cat_ohe_step \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mohe\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     43\u001b[0m                                          handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "dataset = load_telco_churn_data()\n",
    "result = benchmark_models('telco-churn', dataset['full']['X'], dataset['full']['y'], n_splits=3)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [item for result in results for item in result]\n",
    "record_df = pd.DataFrame.from_records(records)[['dataset_name', 'model_name', 'test_score_mean', 'test_score_std']]\n",
    "record_df.to_csv('ebm-perf-classification-overnight.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2b159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572811c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
